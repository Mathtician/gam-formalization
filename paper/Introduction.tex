\section{Introduction}

Interest in weak memory models stems from the belief that such models provide greater flexibility in implementation and thus, can lead to higher performance multicore microprocessors than those that support stronger memory models like \emph{Sequential Consistency} (SC) or \emph{Total Store Order} (TSO). 
However, extremely complicated and contentious definitions of POWER and ARM ISAs, which are the most important modern examples of industrially supported weak memory models, have generated somewhat of a backlash against weak memory models. 
As recently as 2017, a trend is emerging in which general-purpose processors are moving away from extremely weak (so-called ``non-atomic'') memory models and back towards simpler options which are much more tractable to understand and analyze.

\begin{comment}
Parallel programmers rely exclusively on sequential execution of their threads, and find any reordering of instructions in their codes by compilers or processors as a nuisance to be dealt with for the sake of performance.
It is a fact that programmers would prefer the shared memory systems to support the SC memory model. 
This debate has recently been invigorated by RISC-V, a new open-source and free ISA, whose memory model is still being debated in public.
In this paper we address a technical challenge in this debate by defining a class of weak memory models both operationally and axiomatically, and showing the equivalence of the two. 

We first discuss three challenges in defining a weak memory model such that it has matching operational and axiomatic definitions, and is easy for the programmer to use.
\end{comment}

Over the years, two competing memory model definition approaches have emerged.
%Memory models are typically defined in two forms.
One form is the \emph{operational model}, which is essentially an abstract machine that can run a program and directly produce its legal behaviors.
The other form is the \emph{axiomatic model}, which is a collection of constraints on legal program behaviors.
Each type has its own advantage.
Axiomatic models can use general-purpose combinatorial search tools like model checkers and SMT solvers to check whether a specific program behavior is allowed or disallowed, and they are useful for building computationally-efficient tools~\cite{alglave2014herding,memalloy,lustig2017automated}.
However they are not as suitable for inductive proofs that aim to build up executions incrementally, and many architects find them rather non-intuitive and a big departure from actual hardware. %because that would require guessing all the load values and unrolling all the loops in a program. 
On the other hand, operational models are very natural representations of actual hardware behavior, and their small step semantics are naturally very well suited to building formal inductive proofs~\cite{Nienhuis:2016:OSC:2983990.2983997}.

Given the complementary natures of these two types of definitions, it would be ideal if a memory model could have an axiomatic definition and an operational definition which match each other.
Then different definitions can serve different use cases.
This is indeed the case for strong memory models like SC and TSO, but unfortunately, not so for weak memory models.
The research in weak memory models can then be classified into the following two categories:
\begin{enumerate}
    \item Build accurate axiomatic and operational models of existing architectures.
    \item Specify what memory models ought to look like: proposed memory models should be simple to understand with no obvious restrictions on implementations, and the equivalence of axiomatic and operational models may even be understood intuitively.
\end{enumerate}
While great efforts have been devoted to the first type of research to create models for commercial architectures like POWER and ARM, these models and proofs are still subject to subtle incompatibilities and frequent model revisions that invalidate the efforts~\cite{sarkar2011understanding,alglave2014herding,flur2016modelling,lahav2017repairing}.
More importantly, the veracity of these models is hard to judge because they are often based on information which is not public.
For example, the ARM operational model proposed by Flur et al.~\cite{flur2016modelling} allows many non-atomic memory behaviors that cannot be observed in any ARM hardware, and the paper claims that those behaviors are introduced to match the intentions of ARM's architects.
However, the recently released ARM ISA manual~\cite{armv8ar} clearly forbids those behaviors, invalidating the model completely.

This paper falls in the second category, and is motivated by the aim to reduce the complexity of commercial weak memory models.
The results in this paper are not purely academic -- the growing importance of the open source RISC-V ISA~\cite{riscv} has provided an opportunity to design a clean slate memory model.
The memory model for RISC-V is still being debated, and the members of the RISC-V community who are involved in the debate have expressed a strong desire for both axiomatic and operational definitions of the memory model.

In this paper, we present a framework which provides an axiomatic semantics, an operational semantics, and proofs of equivalence, and all in a way that is \emph{parameterized} by the basic instruction and fence orderings in a given model.
With our model, specifications and proofs are not nearly as fragile and subject to frequent breakage with every subtle tweak to a memory model definition.
Instead, the parameterization allows fence semantics to be simply and easily tweaked as needed.

\subsection{Contributions}
The main contribution of this paper is GAM, a general memory model for systems with atomic memory.
The model is parameterized by fences and basic instruction reorderings.
Both its operational and axiomatic definitions can be restricted to provide definitions of other simpler atomic memory models.
We provide proofs that the operational definition of GAM is \emph{sound} and \emph{complete} with respect to its \emph{axiomatic} definition.
We believe that GAM is the first memory model that allows load-store reordering and for which matching axiomatic and operational definitions have been provided.

%In addition to the formalisms, we empirically test the proofs using model checking to further ensure their correctness.
%We also provide a set of litmus tests to capture allowed and disallowed behaviors and to ensure that the GAM model matches the best practices and understanding of the memory model community.

On top of GAM, we show that GAM can be further simplified by simply preventing load-store reordering.
Such models can be described in terms of Instantaneous Instruction Execution (I2E), a model in which instructions execute instantaneously and in-order, with special memory buffers capturing the weak memory behaviors.
Furthermore, I2E models can additionally be parameterized by dependency orderings (under a commonly satisfied constraint), providing even more flexibility.
We provide proofs of equivalence for our axiomatic and operational definitions of I2E as well.

\noindent\textbf{Paper organization:} 
In Section \ref{sec:background}, we present three issues that complicate the definitions of weak memory models.
In Section \ref{sec:related}, we presented the related work.
In Section \ref{sec:GAM}, we present the axiomatic and operational definitions of our parameterized general atomic memory model GAM, along with the proofs of the equivalence of the two definitions.
In Section \ref{sec:COM}, we present an alternative axiomatic definition of GAM because this definition is better suited for using model checkers.
In Section \ref{sec:instance}, we show how GAM can be restricted to represent other simpler memory models.
In Section \ref{sec:I2E}, we show that if Load-Store reordering is disallowed, then the operational models can be described in the Instantaneous Instruction Execution manner and parameterized by dependency orderings.
Finally we end the paper with brief conclusions in Section \ref{sec:conclusion}.  


\section{Memory Model Background}\label{sec:background}

In the following, we discuss the three specific challenges in defining a weak memory model such that it has matching operational and axiomatic definitions, and  explain briefly how we tackle the challenges.

\subsection{Atomic versus Non-atomic Memory}
Both ARM (until March 2017) and IBM Power use what is known as \emph{non-atomic memory} which does not have a universally-agreed-upon definition~\cite{alglave2014herding,maranget2012tutorial}. 
A major source of complication in weak model definitions stems from the use of non-atomic memory.
This lack of consensus makes it difficult to have matching definitions with non-atomic memory.
In this paper, we define memory models that use \emph{atomic memory}, or more precisely its variant which is known as \emph{multicopy atomic memory}. 
By atomic memory we mean a conceptual \emph{multiported monolithic memory} where loads and stores are executed instantaneously and a load $a$ returns the value of the latest store to address $a$.
Multicopy atomic memory lets a processor that generates a store bypass the value of that store to other newer loads in the same processor, before other processors may see that store value.   
Multicopy atomic memory captures the abstraction of a store buffer in the microarchitecture and is the underlying memory system for the popular TSO memory model used by Intel and AMD~\cite{sewell2010x86}.
In this paper we will use the term atomic memory and multicopy atomic memory interchangeably.

In the RISC-V debate a strong consensus has emerged that the memory model for RISC-V should depend only on atomic memory and therefore in this paper we will discuss only atomic memory models.

\subsection{Instruction Reorderings and Single-thread Semantics}\label{sec:inst-reorder}
Modern high-performance processors invariably execute instructions out of order (aka OOO processors) but they do it such that this reordering is transparent to a single threaded program.
However, in a multithreaded setting these instruction reorderings become visible. 
A major classification of memory models is along the lines of which (memory) instruction reorderings are permitted. 
For example, SC does not allow any reordering, while TSO allows a Load to be reordered with respect to previous Stores (i.e., it allows Store-Load reordering).
WMM~\cite{wmm}, Alpha, ARM, and Power also permit Store-Store and Load-Load reordering, provided the accesses are to different addresses, and all of these, except WMM, also permit Load-Store reordering\cite{armv8ar,power2013version,alpha1998,wmm}. 
The same address Store-Store reordering would clearly destroy the single thread semantics and thus, is prohibited.
The reason for disallowing the same address Load-Load reorderings is subtler, and a variation of WMM can be defined that indeed allows such a reordering.
%Alpha~\cite{alpha} and RMO\cite{RMO} are models defined in the past that additionally allow Load-Store reordering in the presence of atomic memory.

However, it should be noted that all of SC, TSO and WMM have matching axiomatic and operational definitions, while to our knowledge Alpha and RMO have only axiomatic definitions.
This difference is likely to be caused by the added complexity of permitting Load-Store reordering, i.e., issuing a Store to the memory before all the previous Loads have completed.
A consequence of allowing Load-Store reordering is that the value a load gets in a multithreaded setting can depend upon a future store from the same thread.  
This complicates operational definitions. 
Load-Store reordering also complicates axiomatic semantics where a special axiom is often needed to disallow so-called \emph{out-of-thin-air} (OOTA) behavior~\cite{Boehm:2014:OGA:2618128.2618134,alpha1998}.
These two factors add to the difficulty of matching axiomatic and operational definitions. 

The \emph{General Atomic Memory} (GAM) model defined in this paper takes the challenge and allows all four reorderings (i.e., including Load-Store reordering).
To model Load-Store reordering, this paper provides an operational definition of GAM using unbounded Reorder Buffer (ROB) with speculative execution and atomic memory. 
(The memory system itself is not speculative, i.e., once a store has been issued it cannot be retracted.)
%A similar mechanism has been used in the past to define the operational model for Power but there is no matching axiomatic definition for this most recent of operational formulations of Power~\cite{sarkar2011understanding}.
A similar mechanism has been used in the past to define the operational model for Power~\cite{sarkar2011understanding}, but there are separate concerns about that model which are discussed in Section~\ref{sec:related}.
%Although there is an axiomatic model~\cite{mador2012axiomatic} that matches this Power operational model, both models are highly delicate and cannot reach the level of parameterization as GAM does.

\subsection{Fences for Writing Multithreaded Programs}
If we classify memory models based on instruction reordering only then for a given program, GAM allows more program behaviors than WMM, WMM allows more behaviors than TSO, and TSO allows more behaviors than SC.
More behaviors generally mean more flexibility in hardware implementation, however, a programmer needs a way to control instruction reorderings in order to write shared memory multithreaded programs.
The foundations of all multithreaded programming, from Dijkstra~\cite{ReadersAndWriters1965} and Lamport~\cite{lamport1979make} to current Java multithreaded libraries, is based on SC, that is, order-preserving interleaving of instructions in a multithreaded program.
Hence as a minimum, any ISA supporting a memory model weaker than SC must provide \emph{fence} instructions to make it possible to disallow instruction reorderings to enforce SC, if desired. 
Not surprisingly, different models require different types of fences and the execution cost of a fence varies from implementation to implementation. 

Fences are often explained in two entirely different ways.
One way is to define a fence simply to prevent reordering between loads and stores. 
For example, RMO and RISC-V have four individual fence components, FenceSS, FenceLS, FenceSL and FenceLL, to prevent reorderings between Store-Store, Load-Store, Store-Load and Store-Store, respectively (the actual names of fence instructions are different), and as many as fifteen fences can be formed by composing these options.
Such fences specify when two instructions in a dynamic instruction stream in a processor may not be reordered.
Of course, for complete specification, one also has to specify how fences may be reordered with respect to each other or how/whether, for example, FenceSS may be reordered with respect to a Load. 
This view of fences is only about reordering with in a processor and has nothing to do with the memory system.

Specifying how fences control instruction reordering is not sufficient to understand how programs behave.
We need to specify what the meaning of ``a store has completed'', i.e., when the value of a store becomes visible to loads in other processors or to a load in the same processor.
One needs to understand the details of the memory subsystem, such as presence of store buffers, write through caches, etc., to give precise meaning to fences.

The second type of fence definitions is usually explained in terms of their effect on memory.
For example, a Store-Release fence (alternatively known as a Commit) blocks the execution of the following stores until all the preceding instructions have completed.
Similarly, Load-Acquire fence (or Reconcile) blocks the execution of following instructions until all preceding loads are satisfied.
Similarly, there is Full-fence instruction that blocks the execution of all subsequent memory instructions until all the preceding memory instructions have completed.

In addition to subtle differences in the semantics of fences, there can be huge differences in performance penalty of using different types of fences.
For example, a full fence may be overkill in an algorithm where it may be sufficient to keep two sequential stores from being reordered.
Insertion of fences in a multithreaded program by the programmer or the compiler writer is one of the thorniest problems related to weak memory models. 
If too many unnecessary fences are inserted in a program then it would show poor performance, and in the extreme case the whole purpose of having a weak memory model would be lost. 
If too few fences are inserted, then the meaning of a program may change by admitting new behaviors which may not be acceptable. 
The debugging of multithreaded programs is a difficult task in the best of times, insertion of fences creates the possibility of including even more silent bugs which may manifest under very peculiar scheduling conditions. 
Automatic insertion of fences by a compiler for the programming model such as the one embodied in C11 may be feasible but that memory model of C11 is already based on some cost assumptions of various fences, creating a catch-22 situation~\cite{c11}.

The lack of agreement on the set of fences and the nuances between different fences all add to the difficulty of matching axiomatic and operational definitions.
To address these problems, GAM restricts itself to a very simple atomic memory model where there is no ambiguity about when a value is visible to other processors.
Such atomic memory automatically avoids many of the thorniest difficulties (such as cumulativity~\cite{alglave2014herding}) in the definitions of fences.
Since there is still no clear consensus on which set of fences gives the best tradeoff between ease of use and performance, we have parameterized the GAM model with the type of fences.
The axiomatic definition, operational definition and the proofs of equivalence are all also parameterized by the type of fences.


%\mycomment{Arvind: Should we say something about atomics, RMW instructions, Data race free programs etc. ?}
%\mycomment{Dan: I vote no, except maybe to say something towards the end like this: we can easily add RMWs by simply requiring the read and the write to be executed consecutively (operational) or to be consecutive in $\MemOrd$ (axiomatic).  Otherwise people will just thing we're ``cheating'' by presenting a simple model just by leaving out important real complexities like these.  (I don't believe that, but I don't want people to read it that way)}
%Sizhuo: also vote no
